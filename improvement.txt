  为什么不相关的 chunk 相似度这么高（0.64）？
  原因: 实体名称匹配
  说明: chunk 中大量出现"上海芯导电子科技股份有限公司"，问题中也有"上海芯导公司"，嵌入模型对实体名称的匹配权重很高
  ────────────────────────────────────────
  原因: 嵌入模型的泛化特性
  说明: text-embedding-v4 是通用模型，对财报等专业领域文本的理解不够精确
  ────────────────────────────────────────
  原因: 余弦相似度的局限
  说明: 只衡量向量方向，不关心内容的精确匹配，表格、结构化数据也可能产生相似向量
  ────────────────────────────────────────
  原因: chunk 内容"噪点多"
  说明: chunk 中有大量表格、公司名称、地址等，这些可能和问题产生"虚假关联"
  ---
  根本原因：语义检索 ≠ 精确检索

  问题："主营业务分行业、分产品..."
         ↓
  嵌入向量: [0.12, 0.45, 0.33, ...]
         ↓
  与所有 chunk 计算余弦相似度
         ↓
  不相关 chunk：[公司名称][表格][地址]...
  向量方向碰巧接近 → 相似度 0.64

  ---
  改进方向（按优先级）

  1️⃣ 重排序（Reranking） - 最有效

  语义检索（召回更多） → 精排模型（选出最相关的）
  - 用 embedding 粗筛出 top 50-100
  - 再用 cross-encoder 或 Rerank 模型精确评分
  - 只有这个方案能真正解决"不相关文档得分高"的问题

  2️⃣ 混合检索（Hybrid Search）

  语义检索 + 关键词检索（BM25）→ 加权融合
  - 你的问题包含"主营业务、分行业、分产品"等明确关键词
  - BM25 能匹配精确关键词，补充语义检索的不足

  3️⃣ 查询改写（Query Expansion）

  - 把"告诉我上海芯导公司 主营业务分行业、分产品..."
  - 改写成多个子查询，分别检索后合并结果

  4️⃣ Chunk 切分优化

  - 当前 chunk 包含大量表格、无关信息
  - 可以按"章节"或"语义单元"切分，避免一个 chunk 混杂多种内容

  5️⃣ 元数据过滤

  - 如果知道答案在"经营情况讨论与分析"章节
  - 可以用元数据（章节标题）预过滤 chunk

  ---
  我的建议

  短期（快速见效）：
  1. 加重排序（Rerank）- 用 BGE-Reranker 或 Cohere Rerank
  2. 检索 top 30 → rerank → 取 top 5

  长期（根本解决）：
  1. 切换到领域专用 embedding 模型（如有）
  2. 实现混合检索（语义 + BM25）
  3. 优化 chunk 切分策略
